{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.0"},"colab":{"provenance":[]}},"cells":[{"cell_type":"markdown","metadata":{"id":"iM49ACib414u"},"source":["# Boosting\n","\n","por Mónica Tatiana Gutierrez Ballen\n","\n","version 1.0, Agosto 2021\n","\n","This notebook is licensed under a [Creative Commons Attribution-ShareAlike 3.0 Unported License](http://creativecommons.org/licenses/by-sa/3.0/deed.en_US). Special thanks goes to [Rick Muller](http://www.cs.sandia.gov/~rmuller/), Sandia National Laboratories"]},{"cell_type":"markdown","metadata":{"id":"sMpYr8Dq4140"},"source":["¿Por qué estamos aprendiendo sobre ensamblaje?\n","\n","- Método muy popular para mejorar el rendimiento predictivo de los modelos de aprendizaje automático\n","- Proporciona una base para entender modelos más sofisticados"]},{"cell_type":"markdown","metadata":{"id":"TGRpcMPX4142"},"source":["# Parte 5: Boosting\n","\n","Aunque el boosting no tiene restricciones algorítmicas, la mayoría de los algoritmos de boosting consisten en aprender iterativamente clasificadores débiles con respecto a una distribución y añadirlos a un clasificador fuerte final. Cuando se añaden, normalmente se ponderan de alguna manera que suele estar relacionada con la precisión de los aprendices débiles. Después de añadir un aprendiz débil, los datos se vuelven a ponderar: los ejemplos mal clasificados ganan peso y los ejemplos correctamente clasificados pierden peso (algunos algoritmos de refuerzo en realidad disminuyen el peso de los ejemplos repetidamente mal clasificados, por ejemplo, el refuerzo por mayoría y BrownBoost). Así, los futuros aprendices débiles se centran más en los ejemplos que los anteriores aprendices débiles clasificaron mal. (Wikipedia)"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":632},"id":"S4Mo3JAVJE2i","executionInfo":{"status":"ok","timestamp":1666906205629,"user_tz":300,"elapsed":21,"user":{"displayName":"Monica Tatiana Gutierrez Ballen","userId":"09991286276964574731"}},"outputId":"b1b66f3f-ddff-4f79-f425-ab4ff944f72e"},"source":["from IPython.display import Image\n","Image(url= \"https://www.researchgate.net/publication/351542039/figure/fig1/AS:1022852723662850@1620878501807/Flow-diagram-of-gradient-boosting-machine-learning-method-The-ensemble-classifiers.png\", width=900)\n"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<img src=\"https://www.researchgate.net/publication/351542039/figure/fig1/AS:1022852723662850@1620878501807/Flow-diagram-of-gradient-boosting-machine-learning-method-The-ensemble-classifiers.png\" width=\"900\"/>"],"text/plain":["<IPython.core.display.Image object>"]},"metadata":{},"execution_count":1}]},{"cell_type":"markdown","metadata":{"id":"VTpi2wsR4149"},"source":["## Adaboost\n","\n","AdaBoost (adaptive boosting) es un algoritmo de aprendizaje de conjunto que puede utilizarse para la clasificación o la regresión. Aunque AdaBoost es más resistente al sobreajuste que muchos algoritmos de aprendizaje automático, suele ser sensible a los datos ruidosos y a los valores atípicos.\n","\n","AdaBoost se denomina adaptativo porque utiliza múltiples iteraciones para generar un único aprendiz fuerte compuesto. AdaBoost crea el aprendiz fuerte (un clasificador que está bien correlacionado con el clasificador verdadero) añadiendo iterativamente aprendices débiles (un clasificador que está sólo ligeramente correlacionado con el clasificador verdadero). Durante cada ronda de entrenamiento, se añade un nuevo aprendiz débil al conjunto y se ajusta un vector de ponderación para centrarse en los ejemplos que se clasificaron mal en las rondas anteriores. El resultado es un clasificador que tiene mayor precisión que los clasificadores de los aprendices débiles."]},{"cell_type":"markdown","metadata":{"id":"QkA7VQxd414-"},"source":["Algoritmo:\n","\n","* Inicializar todos los pesos ($w_i$) a 1 / n/muestras\n","* Entrenar un clasificador $h_t$ utilizando los pesos\n","* Estimar el error de entrenamiento $e_t$\n","* Establecer $alpha_t = log\\left(\\frac{1-e_t}{e_t}\\right)$\n","* Actualizar los pesos \n","$$w_i^{t+1} = w_i^{t}e^{{left(\\alpha_t \\mathbf{I}\\left(y_i \\ne h_t(x_t)\\right)\\$$\n","* Repetir mientras $e_t<0,5$ y $t<T$\n"]},{"cell_type":"code","metadata":{"id":"3Ak-STjX414_","executionInfo":{"status":"ok","timestamp":1666906207078,"user_tz":300,"elapsed":1462,"user":{"displayName":"Monica Tatiana Gutierrez Ballen","userId":"09991286276964574731"}},"outputId":"de90fa33-9284-454c-a258-68f4480e0d2f","colab":{"base_uri":"https://localhost:8080/"}},"source":["# read in and prepare the churn data\n","# Download the dataset\n","import pandas as pd\n","import numpy as np\n","\n","url = 'https://raw.githubusercontent.com/albahnsen/PracticalMachineLearningClass/master/datasets/churn.csv'\n","data = pd.read_csv(url)\n","\n","# Create X and y\n","\n","# Select only the numeric features\n","X = data.iloc[:, [1,2,6,7,8,9,10]].astype(np.float)\n","# Convert bools to floats\n","X = X.join((data.iloc[:, [4,5]] == 'no').astype(np.float))\n","\n","y = (data.iloc[:, -1] == 'True.').astype(np.int)\n","\n","from sklearn.model_selection import train_test_split\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n","n_samples = X_train.shape[0]"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:12: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n","Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n","  if sys.path[0] == '':\n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:14: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n","Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n","  \n","/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:16: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n","Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n","  app.launch_new_instance()\n"]}]},{"cell_type":"code","metadata":{"id":"aIet5eDR415A"},"source":["n_estimators = 10\n","weights = pd.DataFrame(index=X_train.index, columns=list(range(n_estimators)))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zPYGO8Zp415B"},"source":["t = 0\n","weights[t] = 1 / n_samples"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Kkb60lfU415C"},"source":["Entrenar el clasificador"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SgZiDcBz415C","executionInfo":{"status":"ok","timestamp":1666906207520,"user_tz":300,"elapsed":450,"user":{"displayName":"Monica Tatiana Gutierrez Ballen","userId":"09991286276964574731"}},"outputId":"315c0f60-1fa6-460d-ea8f-350037699e76"},"source":["from sklearn.tree import DecisionTreeClassifier\n","trees = []\n","trees.append(DecisionTreeClassifier(max_depth=1))\n","trees[t].fit(X_train, y_train, sample_weight=weights[t].values)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["DecisionTreeClassifier(max_depth=1)"]},"metadata":{},"execution_count":5}]},{"cell_type":"markdown","metadata":{"id":"npPS5N2N415D"},"source":["Error de estimación"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nN3ClJXs415D","executionInfo":{"status":"ok","timestamp":1666906207522,"user_tz":300,"elapsed":35,"user":{"displayName":"Monica Tatiana Gutierrez Ballen","userId":"09991286276964574731"}},"outputId":"132cc824-4a80-4675-bef0-ffe6dca1958f"},"source":["from sklearn.metrics import accuracy_score\n","y_pred_ = trees[t].predict(X_train)\n","error = []\n","error.append(1 - accuracy_score(y_pred_, y_train))\n","error[t]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.13613972234661886"]},"metadata":{},"execution_count":6}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gJKk2Phs415F","executionInfo":{"status":"ok","timestamp":1666906207523,"user_tz":300,"elapsed":25,"user":{"displayName":"Monica Tatiana Gutierrez Ballen","userId":"09991286276964574731"}},"outputId":"b746c213-2f02-45b2-d4ef-731e88da12f0"},"source":["alpha = []\n","alpha.append(np.log((1 - error[t]) / error[t]))\n","alpha[t]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["1.8477293114995077"]},"metadata":{},"execution_count":7}]},{"cell_type":"markdown","metadata":{"id":"-zzs7tF0415F"},"source":["Actualizar los pesos"]},{"cell_type":"code","metadata":{"id":"H1gDv3tz415F"},"source":["weights[t + 1] = weights[t]\n","filter_ = y_pred_ != y_train"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"yXZ_oCb_415G"},"source":["weights.loc[filter_, t + 1] = weights.loc[filter_, t] * np.exp(alpha[t])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"272pl2iW415I"},"source":["Normalizar los pesos"]},{"cell_type":"code","metadata":{"id":"i4utdcYT415I"},"source":["weights[t + 1] = weights[t + 1] / weights[t + 1].sum()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"B8GeUAax415J"},"source":["**Iteración 2 - n_estimadores**"]},{"cell_type":"code","metadata":{"id":"W0qWd0fn415K"},"source":["for t in range(1, n_estimators):\n","    trees.append(DecisionTreeClassifier(max_depth=1))\n","    trees[t].fit(X_train, y_train, sample_weight=weights[t].values)\n","    y_pred_ = trees[t].predict(X_train)\n","    error.append(1 - accuracy_score(y_pred_, y_train))\n","    alpha.append(np.log((1 - error[t]) / error[t]))\n","    weights[t + 1] = weights[t]\n","    filter_ = y_pred_ != y_train\n","    weights.loc[filter_, t + 1] = weights.loc[filter_, t] * np.exp(alpha[t])\n","    weights[t + 1] = weights[t + 1] / weights[t + 1].sum()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ID1WxLBf415K","executionInfo":{"status":"ok","timestamp":1666906207876,"user_tz":300,"elapsed":43,"user":{"displayName":"Monica Tatiana Gutierrez Ballen","userId":"09991286276964574731"}},"outputId":"e2bd7a2d-c0ca-4b81-9a41-34f58d4c077a"},"source":["error"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[0.13613972234661886,\n"," 0.15629198387819077,\n"," 0.8437080161218092,\n"," 0.8437080161218092,\n"," 0.8437080161218092,\n"," 0.8437080161218092,\n"," 0.8437080161218092,\n"," 0.8437080161218092,\n"," 0.8437080161218092,\n"," 0.8437080161218092]"]},"metadata":{},"execution_count":12}]},{"cell_type":"markdown","metadata":{"id":"SDFRs_ko415L"},"source":["### Crear clasificación\n","\n","Sólo los clasificadores cuando el error es < 0,5"]},{"cell_type":"code","metadata":{"id":"MYYbG0LD415M"},"source":["new_n_estimators = np.sum([x<0.5 for x in error])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jgpXw92p415M"},"source":["y_pred_all = np.zeros((X_test.shape[0], new_n_estimators))\n","for t in range(new_n_estimators):\n","    y_pred_all[:, t] = trees[t].predict(X_test)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"15u25u-p415N","executionInfo":{"status":"ok","timestamp":1666906207879,"user_tz":300,"elapsed":35,"user":{"displayName":"Monica Tatiana Gutierrez Ballen","userId":"09991286276964574731"}},"outputId":"c492f117-1c62-44dd-c955-c59f7822cd58","colab":{"base_uri":"https://localhost:8080/"}},"source":["y_pred = (np.sum(y_pred_all * alpha[:new_n_estimators], axis=1) >= 1).astype(np.int)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n","Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n","  \"\"\"Entry point for launching an IPython kernel.\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dzauy4Yf415N","executionInfo":{"status":"ok","timestamp":1666906207881,"user_tz":300,"elapsed":31,"user":{"displayName":"Monica Tatiana Gutierrez Ballen","userId":"09991286276964574731"}},"outputId":"d4959684-14f3-49b5-a8d6-ede7a94541be"},"source":["from sklearn.metrics import f1_score\n","f1_score(y_pred, y_test.values), accuracy_score(y_pred, y_test.values)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(0.5105105105105104, 0.8518181818181818)"]},"metadata":{},"execution_count":16}]},{"cell_type":"markdown","metadata":{"id":"0vselsay415O"},"source":["### Uso de sklearn"]},{"cell_type":"code","metadata":{"id":"rrWSzQXM415O"},"source":["from sklearn.ensemble import AdaBoostClassifier"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ivVVCzZU415O","executionInfo":{"status":"ok","timestamp":1666906208176,"user_tz":300,"elapsed":33,"user":{"displayName":"Monica Tatiana Gutierrez Ballen","userId":"09991286276964574731"}},"outputId":"9880eb9f-1a16-4f49-bd53-733d9ca72cf2"},"source":["clf = AdaBoostClassifier()\n","clf"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["AdaBoostClassifier()"]},"metadata":{},"execution_count":18}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sXo6Zl6l415O","executionInfo":{"status":"ok","timestamp":1666906208180,"user_tz":300,"elapsed":26,"user":{"displayName":"Monica Tatiana Gutierrez Ballen","userId":"09991286276964574731"}},"outputId":"19db0686-1105-412a-aa99-f89ff648f5d1"},"source":["clf.fit(X_train, y_train)\n","y_pred = clf.predict(X_test)\n","f1_score(y_pred, y_test.values), accuracy_score(y_pred, y_test.values)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(0.29107981220657275, 0.8627272727272727)"]},"metadata":{},"execution_count":19}]},{"cell_type":"markdown","metadata":{"id":"wMH5USXA415P"},"source":["### Gradient Boosting"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3ll3tSsh415P","executionInfo":{"status":"ok","timestamp":1666906208371,"user_tz":300,"elapsed":207,"user":{"displayName":"Monica Tatiana Gutierrez Ballen","userId":"09991286276964574731"}},"outputId":"1bfe5c59-71d3-4c1b-98ba-dfee3eb4f324"},"source":["from sklearn.ensemble import GradientBoostingClassifier\n","\n","clf = GradientBoostingClassifier()\n","clf"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["GradientBoostingClassifier()"]},"metadata":{},"execution_count":20}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Phj6uw7D415Q","executionInfo":{"status":"ok","timestamp":1666906208800,"user_tz":300,"elapsed":433,"user":{"displayName":"Monica Tatiana Gutierrez Ballen","userId":"09991286276964574731"}},"outputId":"e2cb3142-7554-4d28-9b16-1f974b3f9b3d"},"source":["clf.fit(X_train, y_train)\n","y_pred = clf.predict(X_test)\n","f1_score(y_pred, y_test.values), accuracy_score(y_pred, y_test.values)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(0.5349794238683128, 0.8972727272727272)"]},"metadata":{},"execution_count":21}]},{"cell_type":"markdown","metadata":{"id":"ZE5lDKEF4AnO"},"source":["## Resumen"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":442},"id":"XdY-QdrB4Bfx","executionInfo":{"status":"ok","timestamp":1666906208801,"user_tz":300,"elapsed":18,"user":{"displayName":"Monica Tatiana Gutierrez Ballen","userId":"09991286276964574731"}},"outputId":"858d3ee9-e699-4f21-dcb1-2f42d8289ce1"},"source":["from IPython.display import Image\n","Image(url= \"https://mateusmaiads.github.io/ensemble_qualify/ensemble_methods-2-01.png\", width=900)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<img src=\"https://mateusmaiads.github.io/ensemble_qualify/ensemble_methods-2-01.png\" width=\"900\"/>"],"text/plain":["<IPython.core.display.Image object>"]},"metadata":{},"execution_count":22}]},{"cell_type":"markdown","metadata":{"id":"brshqQyh4YeO"},"source":["## Comparación del ensamblaje manual con un enfoque de modelo único\n","\n","**Ventajas del ensamblaje manual**\n","\n","- Aumenta la precisión predictiva\n","- Facilidad de inicio\n","\n","**Desventajas del ensamblaje manual**\n","\n","- Disminuye la interpretabilidad\n","- Se tarda más en entrenar\n","- Tarda más en predecir\n","- Es más complejo de automatizar y mantener\n","- Las pequeñas ganancias de precisión pueden no compensar la complejidad añadida"]}]}